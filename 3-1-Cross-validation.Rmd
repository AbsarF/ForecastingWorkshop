---
title: "Forecasting: principles and practice"
author: "Rob J Hyndman"
date: "3.1&nbsp; Time series cross-validation"
fontsize: 14pt
output:
  beamer_presentation:
    fig_width: 7
    fig_height: 3.5
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, warning=FALSE, message=FALSE)
library(fpp2)
source("nicefigs.R")
```

#Time series cross-validation

##Cross-validation

\structure{Traditional evaluation}

```{r, fig.height=3}
train = 1:20
test = 21:25
plot(0,0,xlim=c(0,28),ylim=c(0,1),xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
arrows(0,0,27,0,0.05)
points(train,rep(0,20),pch=19,col="blue")
points(test, rep(0,5), pch=19, col="red")
text(28,0,"time")
text(10,.1,"Training data",col="blue")
text(23,.1,"Test data",col="red")
```

\structure{Leave-one-out cross-validation}

```{r, fig.height=4.5}
ord <- sample(1:25,25)
plot(0,0,xlim=c(0,28),ylim=c(0,.9),xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
for(j in 1:25)
{
  test = (1:25)[ord[j]]
  train = (1:25)[-test]
  arrows(0,1-j/25,27,1-j/25,0.05)
  points(train,rep(1-j/25,length(train)),pch=19,col="blue")
  points(test, rep(1-j/25,length(test)), pch=19, col="red")
  #text(28,1-j/11,"time")
}
```

```{r}
# Produce CV graphics

savepdf("cv0",height=9.5,width=15)
plot(0,0,xlim=c(0,28),ylim=c(0,1),xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
for(j in 1:20)
{
  test <- (6+j):26
  train <- 1:(5+j)
  arrows(0,1-j/20,27,1-j/20,0.05)
  points(train,rep(1-j/20,length(train)),pch=19,col="blue")
  points(test, rep(1-j/20,length(test)), pch=19, col="gray")
}
text(28,.95,"time")
endpdf()

for(i in 1:6)
{
  fname <- paste("cv",i,sep="")
  savepdf(fname,height=9.5,width=15)
  plot(0,0,xlim=c(0,28),ylim=c(0,1),
       xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
  #cols <- brewer.pal(7,"Dark2")[-3]
  for(j in 1:20)
  {
    test <- (6+j):26
    train <- 1:(5+j)
    arrows(0,1-j/20,27,1-j/20,0.05)
    points(train,rep(1-j/20,length(train)),pch=19,col="blue")
    if(length(test) >= i)
      points(test[i], 1-j/20, pch=19, col="red")
    if(length(test) >= i)
      points(test[-i], rep(1-j/20,length(test)-1), pch=19, col="gray")
    else
      points(test, rep(1-j/20,length(test)), pch=19, col="gray")
  }
  text(28,.95,"time")
  endpdf()
}
```

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv0}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv1}

\begin{block}{}$h=1$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv2}

\begin{block}{}$h=2$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv3}

\begin{block}{}$h=3$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv4}

\begin{block}{}$h=4$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv5}

\begin{block}{}$h=5$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv6}

\begin{block}{}$h=6$\end{block}

\vspace*{10cm}

##Cross-validation

\structure{Time series cross-validation}

\includegraphics[width=10.34cm]{cv6}

\begin{alertblock}{}
Also known as ``Evaluation on a rolling forecast origin''
\end{alertblock}

\vspace*{10cm}

##Some connections

###Cross-sectional data
  * Minimizing the AIC is asymptotically equivalent to minimizing MSE via leave-one-out cross-validation.\newline (Stone, 1977).

\pause

###Time series cross-validation

  * Minimizing the AIC is asymptotically equivalent to minimizing MSE via one-step cross-validation.\newline (Akaike, 1969, 1973).

##Time series cross-validation

Assume $k$ is the minimum number of observations for a training set.

\begin{block}{}
\begin{itemize}
  \item Select observation $k+i$ for test set, and use observations at times $1,2,\dots,k+i-1$ to estimate model.
  \item Compute error on forecast for time $k+i$.
  \item Repeat for $i=0,1,\dots,T-k$ where $T$ is total number of observations.
  \item  Compute accuracy measure over all errors.
\end{itemize}
\end{block}

##Example: Pharmaceutical sales

```{r}
autoplot(a10) + xlab("Year") +
  ylab("$ million") +
  ggtitle("Antidiabetic drug sales")
```

##Example: Pharmaceutical sales

\begin{block}{Which of these models is best?}
\begin{itemize}
  \item Linear model with trend and seasonal dummies applied to log data.
  \item ARIMA model applied to log data
  \item ETS model applied to original data
\end{itemize}
\end{block}\pause

  * Set $k=48$ as minimum training set.
  * Forecast 12 steps ahead based on data to time $k+i-1$ for $i=1,2,\dots,156$.
  * Compare MAE values for each forecast horizon.

##Example: Pharmaceutical sales
\fontsize{10}{10}\sf

```r
fc1 <- function(y, h) {
  fit <- tslm(y ~ trend + season)
  return(forecast(fit, h=h))
}
fc2 <- function(y, h) {
  fit <- auto.arima(y)
  return(forecast(fit, h=h))
}
fc3 <- function(y, h) {
  fit <- ets(y)
  return(forecast(fit, h=h))
}
e1 <- tsCV(a10, fc1, h=1)
e2 <- tsCV(a10, fc2, h=1)
e3 <- tsCV(a10, fc3, h=1)
mae1 <- mean(abs(e1))
mae2 <- mean(abs(e2))
mae3 <- mean(abs(e3))
```

 * Repeat for each forecast horizon $h$.
 * Inefficient because of re-fitting models


##Example: Pharmaceutical sales
\scriptsize

```r
k <- 48
n <- length(a10)
mae1 <- mae2 <- mae3 <- matrix(NA,n-k-12,12)
for(i in 1:(n-k-12))
{
  xshort <- window(a10,end=1995+(5+i)/12)
  xnext <- window(a10,start=1995+(6+i)/12,end=1996+(5+i)/12)
  fit1 <- tslm(xshort ~ trend + season, lambda=0)
  fcast1 <- forecast(fit1,h=12)
  fit2 <- auto.arima(xshort,D=1, lambda=0)
  fcast2 <- forecast(fit2,h=12)
  fit3 <- ets(xshort)
  fcast3 <- forecast(fit3,h=12)
  mae1[i,] <- abs(fcast1[['mean']]-xnext)
  mae2[i,] <- abs(fcast2[['mean']]-xnext)
  mae3[i,] <- abs(fcast3[['mean']]-xnext)
}
```

##Example: Pharmaceutical sales

```{r}
k <- 48
n <- length(a10)
mae1 <- mae2 <- mae3 <- matrix(NA,n-k-12,12)
for(i in 1:(n-k-12))
{
  xshort <- window(a10,end=1995+(5+i)/12)
  xnext <- window(a10,start=1995+(6+i)/12,end=1996+(5+i)/12)
  fit1 <- tslm(xshort ~ trend + season, lambda=0)
  fcast1 <- forecast(fit1,h=12)
  fit2 <- auto.arima(xshort,D=1, lambda=0)
  fcast2 <- forecast(fit2,h=12)
  fit3 <- ets(xshort)
  fcast3 <- forecast(fit3,h=12)
  mae1[i,] <- abs(fcast1[['mean']]-xnext)
  mae2[i,] <- abs(fcast2[['mean']]-xnext)
  mae3[i,] <- abs(fcast3[['mean']]-xnext)
}
plot(1:12,colMeans(mae1),type="l",col=2,xlab="horizon",ylab="MAE",
     ylim=c(0.58,1.0))
lines(1:12,colMeans(mae2),type="l",col=3)
lines(1:12,colMeans(mae3),type="l",col=4)
legend("topleft",legend=c("LM","ARIMA","ETS"),col=2:4,lty=1)
```

##\normalsize Variations on time series cross validation
\fontsize{10}{11}\sf

  * Keep training window of fixed length.

```r
xshort <- window(a10,start=i+1/12,end=1995+(5+i)/12)
```

  * Compute one-step forecasts in out-of-sample period.

```r
for(i in 1:(n-k))
{
  xshort <- window(a10,end=1995+(5+i)/12)
  xlong <- window(a10,start=1995+(6+i)/12)
  fit2 <- auto.arima(xshort,D=1, lambda=0)
  fit2a <- Arima(xlong,model=fit2)
  fit3 <- ets(xshort)
  fit3a <- ets(xlong,model=fit3)
  mae2a[i,] <- abs(residuals(fit3a))
  mae3a[i,] <- abs(residuals(fit2a))
}
```



#Lab session 13
##

\fontsize{48}{60}\sf\centering
\textbf{Lab Session 13}


